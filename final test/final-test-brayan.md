# Machine Learning for Masters Final Test

## Name: Brayan Duran Medina

### 2. What is the gradient? How is it used in optimization?

The gradient of a function is a vector of its partial derivatives. It points in the direction of the greatest rate of increase of the function. In optimization, the gradient is used to find the minimum of the function. The idea is to move in the opposite direction of the gradient to reach the minimum.

### 4. What is validation? Cross validation?

Validation is a technique used to evaluate the performance of a model. It is done on a separate dataset from the training set. Cross validation is a technique used to evaluate the performance of a model when the dataset is small or when the model is sensitive to the training set. It is done by splitting the dataset into k parts and using each part as a validation set.

### 6. What are precision and recall metrics?

Precision and recall are metrics used to evaluate the performance of a classification model. Precision is the ratio of true positive to the sum of true positive and false positive. Recall is the ratio of true positive to the sum of true positive and false negative.

### 8. How are parameters different from hyperparameters? E.g. what are parameters in linear models and decision trees? Hyperparameters?

### 10. What is backpropagation? How does it work? E.g. how would gradient propagate through a linear layer? Through ReLU?

### 12. What is dropout? How does it work in a neural network? Does it change its behaviour on the inference (test) stage?

### 14. How does RNN work? Can you combine CNN and RNN somehow?
